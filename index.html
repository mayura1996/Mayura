<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mayura Manawadu</title>

  <meta name="author" content="Mayura Manawadu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Mayura Manawadu
                    <img src="images/MayuraManawadu.jpg" alt="Mayura Manawadu" class="mobile-profile-photo" style="width:150px; height:150px; object-fit: cover; border-radius: 50%; display: none;">

                  </p>
                  <!-- <p>I'm a Graduate Research Assistant at <a href="https://vision.knu.ac.kr/%ec%bb%b4%ed%93%a8%ed%84%b0-%eb%b0%8f-%eb%a1%9c%eb%b4%87-%eb%b9%84%ec%a0%84-%ec%9d%b4%eb%9e%80/">Computer And Robot Vision Laboratory</a> in KNU, South Korea, where I get specialized in Computer Vision Research while reading my MS.
                </p>
                <p>
                  At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                </p> -->
                  <p>Hey! I'm pursuing an MS in Computer Vision at KNU, South Korea, under <a
                      href="https://vision.knu.ac.kr/%ec%bb%b4%ed%93%a8%ed%84%b0-%eb%b0%8f-%eb%a1%9c%eb%b4%87-%eb%b9%84%ec%a0%84-%ec%9d%b4%eb%9e%80/">Prof.
                      Soon-Yong Park</a>. I'm part of the <a
                      href="https://vision.knu.ac.kr/%ec%bb%b4%ed%93%a8%ed%84%b0-%eb%b0%8f-%eb%a1%9c%eb%b4%87-%eb%b9%84%ec%a0%84-%ec%9d%b4%eb%9e%80/">Computer
                      And Robot Vision Laboratory</a>, focusing on 3D computer vision to interpret the world through
                    camera lenses.</p>
                  <p>My current project blends robotics, XR/AR, and AI to develop intelligent systems that learn from
                    human input and adapt to new situations. I specialize in 6D pose estimation and deep learning to
                    enhance machine interaction with their surroundings. My aim is to simplify and naturalize our use of
                    technology. Check out my work to see these concepts in action.</p>
                  <p>Prior to this, I was with <a href="https://www.lseg.com/en">London Stock Exchange Technology (LSEG
                      Technology)</a> for 1.5 years, working on Surveillance Systems and Market Maker Monitoring for the
                    Qatar Stock Exchange, leveraging my data science skills. My journey in tech began with a Computer
                    Engineering degree from the <a href="https://eng.sjp.ac.lk/computereng/">University of Sri
                      Jayewardenepura</a>, Sri Lanka, where I achieved a First Class Degree, was second in my
                    department, and received a Gold Medal for my academic and extracurricular efforts. This background
                    is pivotal in my journey towards crafting user-friendly and smart tech solutions.</p>
                  <p>Deep Learning, Computer Vision, and AR/XR content creation are my main interests.</p>

                  <p style="text-align:center">
                    <a href="mailto:mmayurapavan@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/Mayura_s_CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=5gONoloAAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/mayuramanawadu/">Linkedin</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/mayura_pavan">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://github.com/mayura1996">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/MayuraManawadu.jpg">
                    <img style="width:200px; height:200px; object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/MayuraManawadu.jpg" class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in 3D Computer Vision, Deep Learning, 6DoF Pose Estimation and XR Contents. Most of
                    my research is about inferring the physical world (shape, motion, color, light, etc) from images,
                    usually with radiance fields. Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr onmouseout="abhises_stop()" onmouseover="abhises_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='abhises_image'><video width=100% muted autoplay loop>
                        <source src="images/focalpose2.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/focalpose.png' width=100% height=60%>
                  </div>
                  <script type="text/javascript">
                    function abhises_start() {
                      document.getElementById('abhises_image').style.opacity = "1";
                    }

                    function abhises_stop() {
                      document.getElementById('abhises_image').style.opacity = "0";
                    }
                    abhises_stop()
                  </script>
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="6DoF/index.html">
                    <span class="papertitle">Enhancing 6DoF Pose and Focal Length Estimation from Uncontrolled RGB Images for Robotics Vision</span>
                  </a>
                  <br>
                  <strong>Mayura Manawadu</strong>,
                  <a href="https://scholar.google.com/citations?user=fCgO27IAAAAJ&hl=en">Soon-Yong Park</a>
                  <br>
                  <a href="6DoF/index.html">project page</a>
                  /
                  <a href="https://www.youtube.com/embed/3VhgjcyQQ4Q?si=r0srkJI4Qg3rd7bm&amp;start=113">video</a>

                  /
                  <!-- <a href="https://ieeexplore.ieee.org/abstract/document/10393583">IEEEExplore</a> -->
                  <p></p>
                  <p>
                    We present a two-stage approach for accurate 6DoF pose estimation in robotics, addressing challenges with single RGB images in uncontrolled environments. By decoupling projection parameters and using a render and compare strategy, our method significantly improves accuracy and adaptability, as demonstrated by both quantitative and qualitative results.                </td>
              </tr>


              <tr onmouseout="abhises_stop()" onmouseover="abhises_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='abhises_image'><video width=100% muted autoplay loop>
                        <source src="images/abhises2.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/abhises.png' width=100% height=60%>
                  </div>
                  <script type="text/javascript">
                    function abhises_start() {
                      document.getElementById('abhises_image').style.opacity = "1";
                    }

                    function abhises_stop() {
                      document.getElementById('abhises_image').style.opacity = "0";
                    }
                    abhises_stop()
                  </script>
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="abhises/index.html">
                    <span class="papertitle">Abhises : An Intelligent Virtual Tour Guide</span>
                  </a>
                  <br>
                  <strong>Mayura Manawadu</strong>,
                  <a href="https://sites.google.com/view/udayawijenayake/">Udaya Wijenayake</a>
                  <a>Gihan Chathuranga</a>
                  <a>Charitha Weerasooriya</a>
                  <a>Minura Wijesinghe</a>
                  <a>Poorna Perera</a>
                  <a>Sandun Wijerathne</a>
                  <br>
                  <a href="abhises/index.html">project page</a>
                  /
                  <a href="https://www.youtube.com/embed/3VhgjcyQQ4Q?si=r0srkJI4Qg3rd7bm&amp;start=113">video</a>

                  /
                  <!-- <a href="https://ieeexplore.ieee.org/abstract/document/10393583">IEEEExplore</a> -->
                  <p></p>
                  <p>
                    An Intelligent Augmented Reality Tourist Guide, leveraging Computer Vision and Deep NLP to simulate a real guide's behavior. Capable of environment detection and interaction, it was developed as a final year undergrad project.                  </p>
                </td>
              </tr>

              

              <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='smerf_image'><video width=100% muted autoplay loop>
                        <source src="images/VoiceAssitedRealtimeAccidentPredictionSystem.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/accident.png' width=100% height=60%>
                  </div>
                  <script type="text/javascript">
                    function smerf_start() {
                      document.getElementById('smerf_image').style.opacity = "1";
                    }

                    function smerf_stop() {
                      document.getElementById('smerf_image').style.opacity = "0";
                    }
                    smerf_stop()
                  </script>
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="zipnerf/index.html">
                    <span class="papertitle">Predictive Analysis of Accidents Based on US Accident Data</span>
                  </a>
                  <br>
                  <strong>Mayura Manawadu</strong>,
                  <a href="https://sites.google.com/view/udayawijenayake/">Udaya Wijenayake</a>
                  <br>
                  <a href="zipnerf/index.html">project page</a>
                  /
                  <a href="https://youtu.be/syQGJfk4cGQ">video</a>
                  /
                  <a href="https://ieeexplore.ieee.org/abstract/document/10393583">IEEEExplore</a>
                  <p></p>
                  <p>
                    This research develops a predictive system utilizing US accident data to accurately forecast road
                    accidents and enhance safety through advanced route recommendations and real-time alerts.
                  </p>
                </td>
              </tr>



            
              <tr onmouseout="traffic_stop()" onmouseover="traffic_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='traffic_image'><video width=100% muted autoplay loop>
                        <source src="images/TrafficCropped.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/Traffic.png' width=100% height=60%>
                  </div>
                  <script type="text/javascript">
                    function traffic_start() {
                      document.getElementById('traffic_image').style.opacity = "1";
                    }

                    function traffic_stop() {
                      document.getElementById('traffic_image').style.opacity = "0";
                    }
                    traffic_stop()
                  </script>
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="trafficsign/index.html">
                    <span class="papertitle">Voice-Assisted Real-Time Traffic Sign Recognition System Using
                      Convolutional Neural Network</span>
                  </a>
                  <br>
                  <strong>Mayura Manawadu</strong>,

                  <a href="https://sites.google.com/view/udayawijenayake/">Udaya Wijenayake</a>
                  <br>
                  <a href="trafficsign/index.html">project page</a>
                  /
                  <a href="https://youtu.be/syQGJfk4cGQ">video</a>
                  /
                  <a href="https://ieeexplore.ieee.org/abstract/document/10393583">ResearchGate</a>
                  <p></p>
                  <p>
                    This study introduces a voice-assisted traffic sign recognition system using CNNs, achieving real-time detection with high accuracy, aimed at improving road safety and aiding in the development of autonomous vehicles.
                  </p>
                </td>
              </tr>
              
            </tbody>
            
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:0px; text-align:center;"> <!-- Center align content -->
                    <br>
                    <p style="font-size:small; margin: 0 auto; text-align: center;">
                      Design and source code from <a href="https://jonbarron.info/">Jon Barron's</a> website
                    </p>
                    
                  </td>
                </tr>
              </tbody>
            </table>
            
</body>

</html>